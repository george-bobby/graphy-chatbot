{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love programming in French is: \"J'aime programmer.\"\n",
      "That's great! I can help you translate \"I love programming\" into German. The translation is \"Ich liebe Programmieren\". If you have any other phrases or concepts related to programming that you would like me to translate, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "# Setting up the API key\n",
    "if \"GROQ_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter your Groq API key: \")\n",
    "\n",
    "# Optional: Setting LangSmith API key for tracing (uncomment if needed)\n",
    "# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\n",
    "# os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "\n",
    "# Installing the langchain-groq package\n",
    "# !pip install -qU langchain-groq  # Uncomment this in your notebook or terminal\n",
    "\n",
    "# Importing and instantiating the ChatGroq model\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"mixtral-8x7b-32768\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # Add other parameters as required\n",
    ")\n",
    "\n",
    "# Example Invocation\n",
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "\n",
    "# Printing the response content\n",
    "print(ai_msg.content)\n",
    "\n",
    "# Example chaining with ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that translates {input_language} to {output_language}.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"input_language\": \"English\",\n",
    "        \"output_language\": \"German\",\n",
    "        \"input\": \"I love programming.\",\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transitioning from OpenAI to Groq, or any other machine learning platform, can involve several steps, depending on the specifics of your use case and the resources you have available. Here's a general guide to help you through the process:\n",
      "\n",
      "1. **Understand Groq's architecture and capabilities**: Familiarize yourself with Groq's hardware and software, including its tensor processor unit (TPU) and the Groq Operator (GO) programming language. Learn how it differs from OpenAI's platform in terms of performance, supported operations, and development workflow.\n",
      "\n",
      "2. **Assess your current workloads**: Identify the models, applications, and workloads you are currently running on OpenAI's platform. Determine which of these can benefit from Groq's unique architecture and capabilities.\n",
      "\n",
      "3. **Plan for data migration**: If your models and applications rely on specific datasets, you'll need to plan for data migration. Ensure that your data is compatible with Groq's data formats and storage systems.\n",
      "\n",
      "4. **Re-implement models**: Groq's GO language is different from OpenAI's programming languages and frameworks. You'll need to re-implement your models using GO or convert them using available tools or libraries.\n",
      "\n",
      "5. **Optimize for performance**: Groq's TPU is designed for high performance and efficiency. To take full advantage of its capabilities, you may need to optimize your models and applications for the new hardware. This might involve reorganizing data structures, re-tuning hyperparameters, or applying other optimization techniques.\n",
      "\n",
      "6. **Test and validate**: Thoroughly test your models and applications on Groq's platform to ensure they perform as expected. Validate the results against your existing implementations on OpenAI's platform.\n",
      "\n",
      "7. **Monitor and maintain**: Set up monitoring and maintenance procedures for your new Groq-based workloads. This may include tracking performance, identifying and addressing issues, and updating your models and applications as needed.\n",
      "\n",
      "Remember that transitioning from one platform to another can be a complex process, and it's essential to allocate sufficient time and resources for a smooth and successful transition. If you encounter specific challenges or questions during the process, consider reaching out to Groq's support or community resources for assistance.\n"
     ]
    }
   ],
   "source": [
    "# Using the already instantiated ChatGroq model\n",
    "\n",
    "# Example Invocation\n",
    "messages = [\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"human\", \"How do I transition from OpenAI to Groq?\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "\n",
    "# Print the response content\n",
    "print(ai_msg.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
